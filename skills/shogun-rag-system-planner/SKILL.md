---
name: rag-system-planner
description: 特定のフレームワーク、ライブラリ、技術ドキュメント、コードベースに対するRAG（Retrieval-Augmented Generation）システムの構築計画を策定する。「○○のドキュメントをRAGで検索可能にしたい」「○○向けのAIアシスタントを作りたい」「社内ナレッジベースをLLMで活用したい」といった要望に対して、技術調査・アーキテクチャ設計・技術スタック選定・チャンキング戦略・UX設計・インフラ構成・ロードマップ・リスク分析を含む包括的な計画書を出力する。
---

# RAG System Planner

## Overview

特定の技術・フレームワーク・ドキュメント群に対するRAG（Retrieval-Augmented Generation）システムの構築計画を策定するスキル。対象技術のドキュメント体系を分析し、最適なベクトルDB・Embeddingモデル・チャンキング戦略・インフラ構成を選定した上で、段階的なロードマップとリスク分析を含む計画書を出力する。

このスキルは**計画策定**に特化しており、実装そのものは行わない。出力される計画書を基にエンジニアチームが実装を進める前提で設計されている。

## When to Use

以下のいずれかに該当する場合にこのスキルを使用する：

- 「○○のドキュメントをAIで検索可能にしたい」
- 「○○向けのAIアシスタント/Copilotを作りたい」
- 「社内ナレッジベースをLLMで活用したい」
- 「○○フレームワークのRAGシステムを構築したい」
- 「既存ドキュメント群をベクトル化して検索させたい」
- 「開発者向けのコード検索・質問応答システムを作りたい」
- 特定技術のドキュメント + コードベースを対象としたRAG計画の策定が求められた場合

**トリガーキーワード**: RAG, ベクトル検索, Embedding, ナレッジベース, AIアシスタント, ドキュメント検索, コード検索

## Instructions

### Phase 0: 要件ヒアリング

計画策定の前に、以下の情報を確認・収集せよ。不明な場合は依頼者に確認する。

```
【必須ヒアリング項目】
1. 対象技術/フレームワーク名
2. ドキュメントソースの所在（公式サイト、GitHub、社内Wiki等）
3. 対象言語（日本語、英語、多言語等）
4. 主なユーザー像（新規学習者、現役開発者、アーキテクト等）
5. 提供形態の希望（IDE統合、Chat UI、CLI、API等）
6. インフラ制約（クラウドOK/オンプレ必須/ハイブリッド等）
7. 予算感（月額目安があれば）
8. 既存システムとの連携要件
```

### Phase 1: 対象ドキュメント/コードベースの分析

#### Step 1.1: ドキュメントソースの特定と分類

対象技術に関するドキュメントソースを網羅的に特定し、以下のカテゴリに分類する。

| カテゴリ | 例 | 典型的なフォーマット |
|---|---|---|
| 公式ドキュメント | リファレンスマニュアル、ガイド | HTML, RST, Markdown |
| ソースコード | GitHub リポジトリ | Java, Python, TypeScript 等 |
| APIリファレンス | Javadoc, Swagger, OpenAPI | HTML, JSON, YAML |
| 設定ファイル | XML, YAML, JSON の設定例 | XML, YAML, JSON |
| チュートリアル/ガイド | 入門ガイド、ハウツー | HTML, Markdown, PDF |
| 開発標準 | コーディング規約、設計テンプレート | Markdown, PDF, HTML |
| コミュニティコンテンツ | ブログ記事、Q&A、フォーラム | HTML |
| サンプルコード | Example プロジェクト | 各言語のソースコード |

**チェックポイント**:
- [ ] 各ソースのURL/所在地を記録したか
- [ ] ライセンスを確認したか（Apache-2.0, MIT等 → RAG利用可。独自ライセンス → 要確認）
- [ ] 推定ボリューム（ファイル数、リポジトリ数、ページ数）を見積もったか
- [ ] 日本語/英語/多言語の状況を確認したか

#### Step 1.2: ドキュメント構造の詳細分析

各ドキュメントソースについて以下を調査する：

```
【調査項目】
1. ディレクトリ/セクション構造（目次レベルの把握）
2. コンテンツの粒度（1ページ=1トピックか、長大なページか）
3. クロスリファレンスの有無（ドキュメント間リンク）
4. バージョニング方式（複数バージョンのドキュメントがあるか）
5. 更新頻度（頻繁に更新されるか、安定しているか）
6. メタデータの有無（カテゴリ、タグ、著者等）
```

### Phase 2: ベクトルDB選定

以下の決定マトリクスに従って選定する。**必ずWeb検索で最新の比較情報を確認せよ。**

#### 選定基準

```
【Decision Matrix】

Q1: 既存のPostgreSQLインフラがあるか？
  → YES: pgvector を第一候補
  → NO: Q2へ

Q2: ベクトル数の見込みは？
  → <1M vectors: pgvector（コスト効率最優先）
  → 1M-10M vectors: pgvector + pgvectorscale or Weaviate
  → >10M vectors: Milvus or Qdrant or Pinecone

Q3: ハイブリッド検索（BM25 + Vector）が必要か？
  → YES（推奨）: Weaviate（DB側で完結）or pgvector + PostgreSQL FTS
  → NO: 任意

Q4: マネージドサービスが必要か？
  → YES: Pinecone（最も簡単）or クラウドマネージドpgvector
  → NO: セルフホストOSS

Q5: メタデータフィルタリングが重要か？
  → YES: Qdrant（最も柔軟）or Weaviate
  → NO: 任意
```

#### ベクトルDB比較表（スキル実行時にWeb検索で最新化すること）

| DB | タイプ | 最適規模 | ハイブリッド検索 | OSS | コスト |
|---|---|---|---|---|---|
| pgvector | PostgreSQL拡張 | 〜10M vectors | PostgreSQL FTSと組合せ | ✅ | 最低 |
| Weaviate | 専用DB | 中〜大規模 | ネイティブ対応 | ✅ | 中 |
| Qdrant | 専用DB | 中〜大規模 | 部分対応 | ✅ | 中 |
| Milvus | 専用DB | 大規模（10億+） | 部分対応 | ✅ | 中〜高（運用コスト） |
| Pinecone | マネージド | 自動スケール | Sparse+Dense | ❌ | 高（API課金） |
| ChromaDB | 軽量DB | 小〜中規模 | 限定的 | ✅ | 最低 |

### Phase 3: Embeddingモデル選定

#### 選定基準

```
【Decision Matrix】

Q1: 対象言語は何か？
  → 日本語含む多言語: Jina embeddings-v4（OSS, 89言語）or Cohere embed-v4.0（API）
  → 英語のみ: OpenAI text-embedding-3-large or Jina v3
  → 中国語含む: Jina v4 or BGE-M3

Q2: ソースコードの検索が必要か？
  → YES: デュアルモデル方式を推奨
    - ドキュメント用: 多言語対応モデル（Jina v4等）
    - コード用: コード特化モデル（Voyage-code-3, CodeXEmbed, Jina code-embeddings）
  → NO: 単一モデルで可

Q3: オンプレミス/セルフホストが必要か？
  → YES: OSSモデル必須（Jina v4, BGE-M3, CodeXEmbed）
  → NO: API利用可（Voyage, OpenAI, Cohere）

Q4: コンテキスト長の要件は？
  → 長文ドキュメント多い: Jina v4（32K tokens）推奨
  → 通常: 8K tokens程度で十分
```

#### Embeddingモデル比較表（スキル実行時にWeb検索で最新化すること）

| モデル | 用途 | 多言語 | コード | OSS | 特徴 |
|---|---|---|---|---|---|
| Jina embeddings-v4 | 汎用 | ✅ 89言語 | ✅ | ✅ | 32K tokens、マルチモーダル |
| Jina code-embeddings | コード特化 | △ | ✅ | ✅ | 5タスク対応（NL2Code等） |
| Voyage-code-3 | コード特化 | ✅ | ✅（最高精度） | ❌ | CoIRベンチマーク1位 |
| Cohere embed-v4.0 | 汎用 | ✅ 100+言語 | △ | ❌ | エンタープライズ向け |
| OpenAI text-embedding-3-large | 汎用 | ✅ | △ | ❌ | 簡易導入 |
| BGE-M3 | 汎用 | ✅ | △ | ✅ | Dense+Sparse+Multi-vector |
| CodeXEmbed (Salesforce) | コード特化 | △ | ✅（SOTA） | ✅ | 7Bモデル、12言語対応 |

### Phase 4: チャンキング戦略の設計

#### Step 4.1: コンテンツ種別の分類

対象ドキュメントを以下のコンテンツ種別に分類し、それぞれに最適なチャンキング戦略を適用する。

| コンテンツ種別 | 推奨チャンキング戦略 | 推奨チャンクサイズ | オーバーラップ |
|---|---|---|---|
| **構造化ドキュメント**（HTML/RST/Markdown with headings） | Structure-aware（見出しベース） | 512 tokens | 20% |
| **ソースコード** | AST-based（関数/メソッド/クラス単位） | 256-512 tokens | コンテキスト付加 |
| **API リファレンス** | エントリ単位（1関数=1チャンク） | 256 tokens | パッケージ/モジュール情報付加 |
| **設定ファイル**（XML/YAML/JSON） | 構造単位（ルート要素/セクション） | 256 tokens | 親要素コンテキスト付加 |
| **非構造化テキスト**（散文、ブログ等） | Semantic chunking | 512 tokens | 20-30% |
| **サンプルコード/チュートリアル** | ファイル単位 + 論理分割 | 512 tokens | メタデータ付加 |
| **PDF/Word文書** | ページ + セマンティック分割 | 512 tokens | 20% |

#### Step 4.2: メタデータスキーマ設計

各チャンクに付与するメタデータのスキーマを設計する。以下をベースに対象技術固有のフィールドを追加する。

```json
{
  "source": "{データソース名}",
  "source_type": "{documentation | code | api_reference | config | tutorial | standard}",
  "version": "{対象技術のバージョン}",
  "module": "{モジュール/パッケージ名}",
  "category": "{カテゴリ階層}",
  "language": "{ja | en | ...}",
  "file_path": "{元ファイルのパス}",
  "section_hierarchy": ["{セクション階層}"],
  "url": "{元ドキュメントのURL}",
  "last_updated": "{最終更新日}"
}
```

#### Step 4.3: Contextual Chunking の適用判断

以下の場合は Contextual Chunking（各チャンクの先頭に文書レベルコンテキストをLLMで生成して付加）を推奨する：

- ドキュメントが深い階層構造を持ち、チャンク単体では文脈が失われやすい
- 代名詞（「これ」「その」「it」等）が多用されるドキュメント
- 検索精度のベースラインが目標を下回る場合のチューニング手段として

```
Contextual Chunking の適用例:

[Context] {カテゴリ} > {セクション} > {サブセクション}
[Context] {このセクションが扱うトピックの1行要約}
---
[Chunk] {実際のチャンク内容}
```

### Phase 5: RAGパイプライン設計（6層アーキテクチャ）

以下の6層でRAGパイプラインを設計する。対象技術に応じて各層の具体的な技術を選定する。

```
Layer 1: Data Ingestion Layer（データ取込み）
  - 各ドキュメントソースからのデータ収集方法
  - クローラー / GitHub API / スクレイピング / 手動インポート
  - 更新検知・差分取込みの仕組み

Layer 2: Document Processing Layer（ドキュメント処理）
  - ファイルタイプ別パーサー
  - メタデータ抽出
  - クリーニング（不要なHTML要素除去等）
  - チャンキング実行

Layer 3: Embedding Layer（ベクトル化）
  - 選定したEmbeddingモデルによるベクトル生成
  - デュアルモデルの場合のルーティング
  - バッチ処理 / リアルタイム処理の選択

Layer 4: Vector Storage Layer（ベクトル格納）
  - 選定したベクトルDB
  - インデックス設計（コンテンツ種別別インデックス推奨）
  - メタデータストレージ

Layer 5: Retrieval Layer（検索）
  - ハイブリッド検索（BM25 + Vector Similarity）← 標準
  - クエリ解析（質問タイプ判定 → 適切なインデックスへルーティング）
  - リランキング（Cross-Encoder）
  - Query Reformulation（必要に応じて）

Layer 6: Generation Layer（生成）
  - LLM選定（Claude / GPT-4o / ローカルLLM）
  - プロンプトテンプレート設計
  - ソース引用・Attribution機構
  - ハルシネーション抑制策
```

### Phase 6: UX設計

ターゲットユーザーに応じて、以下のインターフェースから提供形態を選定する。

#### インターフェース選定基準

| インターフェース | 最適なケース | 実装コスト | 導入障壁 |
|---|---|---|---|
| **IDE拡張（VS Code等）** | 対象がフレームワーク/ライブラリでユーザーが開発者 | 高 | 低（IDE内で使える） |
| **Chat UI（Web）** | 幅広いユーザー層、非開発者も含む | 中 | 中（URLアクセス） |
| **CLIツール** | 開発者向け、スクリプト連携 | 低 | 中（インストール必要） |
| **API** | 他システムとの連携、プログラマティック利用 | 低 | 高（開発知識必要） |
| **Slack/Teams Bot** | チームコミュニケーションツール内で使いたい | 中 | 低（既存ツール内） |

#### UX設計で含めるべき要素

- **ターゲットユーザー定義**: 誰が使うか（ペルソナ3-5個）
- **利用シーン定義**: どういう状況で使うか
- **インターフェース選定**: 上記から1-3個を選定
- **機能一覧**: 各インターフェースの主要機能
- **フィードバック機構**: 回答品質改善のための仕組み
- **多言語対応方針**: 必要に応じて

### Phase 7: インフラ構成の選択

#### 選定基準

```
【Decision Matrix】

Q1: クラウド利用の制約は？
  → 制約なし: クラウド構成を推奨（AWS or Azure）
  → データ主権要件あり: オンプレ or プライベートクラウド
  → ハイブリッド可: クラウドLLM + オンプレDB

Q2: 既存のクラウド環境は？
  → AWS: Aurora PostgreSQL + pgvector + Bedrock（Claude）
  → Azure: Azure Database for PostgreSQL + pgvector + Azure OpenAI
  → GCP: Cloud SQL + pgvector + Vertex AI
  → なし: 要件に最適なものを選定

Q3: 運用チームのスキルレベルは？
  → 高い（MLOps経験あり）: セルフホスト構成も可
  → 標準: マネージドサービス中心
  → 限定的: フルマネージド構成推奨

Q4: 予算規模は？
  → 月額 $500以下: pgvector + クラウドLLM API
  → 月額 $500-2000: 中規模マネージド構成
  → 月額 $2000+: 本格的な本番構成
```

#### クラウド構成テンプレート

**AWS構成**:
- CDN: CloudFront
- API: API Gateway + Lambda / ECS
- ベクトルDB: Aurora PostgreSQL + pgvector
- LLM: Amazon Bedrock (Claude)
- ストレージ: S3
- 監視: CloudWatch

**Azure構成**:
- CDN: Front Door
- API: API Management + Functions / Container Apps
- ベクトルDB: Azure Database for PostgreSQL + pgvector
- 検索: Azure AI Search（ハイブリッド検索）
- LLM: Azure OpenAI (GPT-4o)
- ストレージ: Blob Storage

**オンプレ構成**:
- リバースプロキシ: Nginx
- アプリ: FastAPI
- ベクトルDB: PostgreSQL + pgvector（セルフホスト）
- Embedding: OSSモデル（Jina v4等）セルフホスト
- LLM: Ollama（ローカル）or VPN経由でクラウドAPI

### Phase 8: コスト見積もり

以下の項目ごとにコスト概算を算出する。

```
【コスト項目】

1. ベクトルDB
   - マネージドDB: インスタンスサイズ × 月額
   - セルフホスト: サーバー費用

2. Embedding API
   - API課金の場合: トークン数 × 単価
   - セルフホスト: GPU/CPUサーバー費用
   - 初回ベクトル化: 全ドキュメントの総トークン数 × 単価
   - 差分更新: 月間更新ドキュメント × 単価

3. LLM API
   - 月間クエリ数 × 平均入出力トークン数 × 単価
   - プロンプトテンプレートのオーバーヘッドを含める

4. コンピュート
   - API サーバー（Lambda/ECS/VM）
   - インジェスションパイプライン

5. ストレージ
   - 生データ保存（S3/Blob）
   - ベクトルDBのストレージ

6. その他
   - CDN/ネットワーク
   - 監視/ログ
   - 開発環境
```

#### コスト概算テンプレート（月額）

| 規模 | ベクトルDB | LLM API | コンピュート | ストレージ | 合計 |
|---|---|---|---|---|---|
| 小規模（PoC） | $50-100 | $50-100 | $20-50 | $5-10 | $125-260 |
| 中規模（本番） | $200-400 | $100-300 | $50-100 | $10-20 | $360-820 |
| 大規模（エンタープライズ） | $500-2000 | $300-1000 | $200-500 | $50-100 | $1050-3600 |

### Phase 9: ロードマップ策定

以下の4フェーズで段階的に構築することを推奨する。

```
Phase 1: PoC（概念実証）
  目標: 最小限のパイプラインで価値を実証
  スコープ:
  - 主要ドキュメントソース1種類のみをベクトル化
  - 基本的な検索 + LLM生成
  - CLIまたはシンプルなChat UIで評価
  - 評価テストセット作成（50問以上推奨）
  - 評価メトリクス: Recall@K, Precision@K, MRR
  成功基準: Recall@10 > 80%, レイテンシ < 3秒

Phase 2: コアシステム構築
  目標: プロダクション品質のバックエンド
  スコープ:
  - 全ドキュメントソースのインジェスション
  - ハイブリッド検索（BM25 + Vector）の実装
  - リランキング導入
  - REST API + 基本Chat UI
  成功基準: 全データソース統合、API安定稼働

Phase 3: UX強化
  目標: ユーザー体験の最大化
  スコープ:
  - IDE拡張 or 主要インターフェースの本格実装
  - フィードバックループ構築
  - 多言語対応
  - ユーザーテスト・改善サイクル

Phase 4: 高度化・拡張
  目標: エコシステムへの浸透
  スコープ:
  - 追加データソースの統合
  - 自動更新パイプライン
  - エンタープライズセキュリティ
  - 高度な機能（コードレビュー支援、標準遵守チェック等）
```

### Phase 10: リスク分析

以下の4カテゴリでリスクを分析し、対策を策定する。

#### リスクカテゴリ

| カテゴリ | 主要リスク | 共通対策 |
|---|---|---|
| **技術リスク** | Embeddingの精度不足、多言語チャンキング、スケール限界、ハルシネーション | PoC段階でのベンチマーク、Faithfulnessスコア評価 |
| **データリスク** | ライセンス制約、古い情報混入、更新追従、機密情報 | ライセンス事前確認、バージョンメタデータ、自動パイプライン |
| **運用リスク** | コスト超過、モデル更新、API価格変動、スキル不足 | コストアラート、LLMプロバイダ抽象化、運用マニュアル |
| **ビジネスリスク** | 競合、市場変化、採用率 | PoC段階でのユーザーテスト、差別化要素の明確化 |

### 計画書の最終構成

上記 Phase 1-10 の結果を以下のセクション構成でレポートにまとめる：

```markdown
# {対象技術名} RAGシステム構築計画書

## 1. 現状調査結果
### 1.1 RAG技術動向（Web検索で最新化）
### 1.2 {対象技術}ドキュメント体系の分析
### 1.3 関連システムとの連携可能性

## 2. 具体的な実装計画
### 2.1 RAGパイプラインアーキテクチャ（6層）
### 2.2 技術スタック選定
### 2.3 チャンキング戦略

## 3. UX設計
### 3.1 ターゲットユーザーと利用シーン
### 3.2 提供インターフェース
### 3.3 UXフロー

## 4. インフラ構成案
### 4.1-4.3 クラウド/オンプレ構成（複数案）
### 4.4 構成比較

## 5. 段階的な構築ロードマップ（4フェーズ）

## 6. 実現可能性の評価
### 6.1 技術的実現可能性
### 6.2 データ面の実現可能性
### 6.3 ビジネス面の実現可能性

## 7. リスクと対策（4カテゴリ）

## 参考資料
```

## Examples

### 入力例 1: フレームワーク向けRAG

```
依頼: 「NablarchフレームワークのRAGシステム構築計画を策定してほしい」

ヒアリング結果:
- 対象: Nablarch（TIS社のJavaフレームワーク）
- ドキュメント: 公式サイト（nablarch.github.io）、GitHub（114リポジトリ）、Fintan、API Javadoc
- 言語: 日本語 + 英語
- ユーザー: 新規/現役Nablarchエンジニア、Xenlon移行後エンジニア
- 提供形態: VS Code拡張（最優先）、Chat UI、CLI、API
- インフラ: クラウド（AWS推奨）
```

```
出力（計画書の主要決定事項）:
- ベクトルDB: PostgreSQL + pgvector（NablarchがRDBMS中心のため親和性高い）
- Embedding: デュアルモデル方式
  - ドキュメント用: Jina embeddings-v4（日本語対応、32Kコンテキスト、OSS）
  - コード用: Voyage-code-3（CoIRベンチマーク最高水準）
- チャンキング: コンテンツ種別別6戦略
  - 公式ドキュメント: Structure-aware（512 tokens, 20% overlap）
  - Javaコード: AST-based（256-512 tokens）
  - XML設定: Tag-based（256 tokens）
  - Javadoc: メソッド単位（256 tokens）
  - 開発標準: Semantic chunking（512 tokens）
  - サンプルコード: ファイル単位 + メソッド分割（512 tokens）
- インフラ: AWS（Aurora PostgreSQL + Bedrock）月額$390-870
- ロードマップ: 4フェーズ（PoC→コアシステム→UX強化→高度化）
- 実現可能性: 高（全技術が成熟、ライセンス問題なし）
```

### 入力例 2: 社内ナレッジベース向けRAG

```
依頼: 「社内のConfluenceとGitHubリポジトリをRAGで検索できるようにしたい」

ヒアリング結果:
- 対象: 社内Confluence（5000ページ）、GitHub（50リポジトリ、Python）
- 言語: 日本語
- ユーザー: 全エンジニア（50名）
- 提供形態: Slack Bot、Chat UI
- インフラ: AWS（既存環境あり）
- 予算: 月額$500以下
```

```
出力（計画書の主要決定事項）:
- ベクトルDB: pgvector（既存AWS + 予算制約）
- Embedding: Jina embeddings-v4（日本語対応、OSS）
  - コード用: Jina code-embeddings-1.5b（OSS、コスト抑制）
- チャンキング:
  - Confluence: Structure-aware（見出しベース、512 tokens）
  - Python コード: AST-based（関数単位、256-512 tokens）
- インフラ: AWS（RDS PostgreSQL + Lambda + Bedrock）月額$300-500
- UX: Slack Bot（最優先）+ シンプルChat UI
```

### 入力例 3: OSSライブラリ向けRAG

```
依頼: 「ReactのドキュメントをRAGで検索できるAIアシスタントを作りたい」

ヒアリング結果:
- 対象: React公式ドキュメント（react.dev）、GitHub
- 言語: 英語
- ユーザー: React学習者、フロントエンド開発者
- 提供形態: Chat UI、VS Code拡張
- インフラ: 制約なし
```

```
出力（計画書の主要決定事項）:
- ベクトルDB: pgvector or ChromaDB（PoCならChroma、本番ならpgvector）
- Embedding: OpenAI text-embedding-3-large（英語のみなら十分、簡易導入）
  - コード用: Voyage-code-3（JSX/TypeScript対応）
- チャンキング:
  - ドキュメント: Structure-aware（MDXの見出しベース）
  - サンプルコード: コードブロック単位
- インフラ: Vercel + Supabase（pgvector） + OpenAI API
- UX: Chat UI（Next.js + Vercel AI SDK）
```

## Guidelines

### 必須ルール

1. **Web検索で最新情報を確認すること**
   - Embeddingモデルの比較情報は半年で陳腐化する
   - ベクトルDBの新バージョン・新機能を必ずチェック
   - 検索クエリ例: `"best embedding models {current_year}"`, `"vector database comparison {current_year}"`, `"RAG best practices {current_year}"`

2. **ライセンス確認を忘れないこと**
   - 対象ドキュメント/コードのライセンスを必ず確認
   - Apache-2.0, MIT → RAG利用可
   - 独自ライセンス → 利用規約を精査
   - 商用コンテンツ → 許可が必要な可能性あり

3. **ハイブリッド検索（BM25 + Vector）を標準とすること**
   - Vector検索のみでは専門用語のキーワードマッチで弱い
   - BM25のみでは意味的類似性を捉えられない
   - 両方を組み合わせることで精度が大幅に向上する

4. **評価テストセットを必ず計画に含めること**
   - 最低50問の質問-回答ペア
   - 質問タイプのバランス: ドキュメント質問、コード質問、設定質問、エラー解決
   - 評価メトリクス: Recall@K, Precision@K, MRR, Faithfulness

5. **コスト概算を必ず含めること**
   - 月額ランニングコストの見積もり
   - 初回ベクトル化コスト
   - スケール時のコスト増加予測

### 品質基準

- 計画書は**日本語**で作成する（依頼が日本語の場合）
- アーキテクチャ図はASCIIアートで表現する
- 比較表は必ずMarkdownテーブルで記述する
- 全ての技術選定には**選定理由**を明記する
- 参考資料は実際にアクセス可能なURLを記載する

### アンチパターン（避けるべきこと）

- 特定ベンダーに偏った推奨（複数選択肢を提示すること）
- ベンチマーク数値のみでの判断（実際のユースケースとの適合性を考慮）
- スケールの過剰設計（PoCは小さく始めること）
- チャンキング戦略の一律適用（コンテンツ種別ごとに最適化すること）
- 運用面の無視（更新パイプライン、モニタリングを計画に含めること）
